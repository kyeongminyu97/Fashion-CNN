{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-05T05:00:20.724302Z","iopub.execute_input":"2022-04-05T05:00:20.724855Z","iopub.status.idle":"2022-04-05T05:00:38.367726Z","shell.execute_reply.started":"2022-04-05T05:00:20.724817Z","shell.execute_reply":"2022-04-05T05:00:38.366910Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Notebook to run Classification on Fashion Images.\n\nData Images are conatined in the foler 'zalando', which contains subfolders: \"hoodies\",\"hoodies-female\",\"longsleeve\",\"shirt\",\"sweatshirt\",\"sweatshirt-female\"\nEach folder contains around 1500-3500 high-resolution images.\n\n## Notebook Contents: \n1. Image Preprocessing and data visualisation\n2. Simple CNN model for multi-label classification\n3. VGG16 model for for multi-label classification\n\n\n","metadata":{}},{"cell_type":"code","source":"#check size of and example image\nimport cv2\nimg = cv2.imread(\"../input/zalando-store-crawl/zalando/hoodies-female/10K21J006-C11@8.jpg\")\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:00:52.409448Z","iopub.execute_input":"2022-04-05T05:00:52.409703Z","iopub.status.idle":"2022-04-05T05:00:52.717816Z","shell.execute_reply.started":"2022-04-05T05:00:52.409674Z","shell.execute_reply":"2022-04-05T05:00:52.717092Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Show example images\nimport matplotlib.pyplot as plt\n\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:00:54.765265Z","iopub.execute_input":"2022-04-05T05:00:54.765771Z","iopub.status.idle":"2022-04-05T05:00:55.059191Z","shell.execute_reply.started":"2022-04-05T05:00:54.765731Z","shell.execute_reply":"2022-04-05T05:00:55.058484Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"DATADIR = \"../input/zalando-store-crawl/zalando\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:01:01.019100Z","iopub.execute_input":"2022-04-05T05:01:01.019658Z","iopub.status.idle":"2022-04-05T05:01:01.023492Z","shell.execute_reply.started":"2022-04-05T05:01:01.019619Z","shell.execute_reply":"2022-04-05T05:01:01.022727Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# df with filename and label may be useful\nimport glob\nhoodies_list= glob.glob(DATADIR+'/hoodies/*.jpg')\nhoodies_f_list= glob.glob(DATADIR+'/hoodies-female/*.jpg')\nsweatshirt_list= glob.glob(DATADIR+'/sweatshirt/*.jpg')\nsweatshirt_f_list=glob.glob(DATADIR+'/sweatshirt-female/*.jpg')\nshirt_list=glob.glob(DATADIR+'/shirt/*.jpg')\nlongsleeve_list=glob.glob(DATADIR+'/longsleeve/*.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:01:12.106930Z","iopub.execute_input":"2022-04-05T05:01:12.107226Z","iopub.status.idle":"2022-04-05T05:01:12.172151Z","shell.execute_reply.started":"2022-04-05T05:01:12.107192Z","shell.execute_reply":"2022-04-05T05:01:12.171468Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf= pd.DataFrame(hoodies_list, columns=['filename'])\ndf['category']= ['hoodies'] * len(hoodies_list)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:01:14.168441Z","iopub.execute_input":"2022-04-05T05:01:14.169006Z","iopub.status.idle":"2022-04-05T05:01:14.186022Z","shell.execute_reply.started":"2022-04-05T05:01:14.168968Z","shell.execute_reply":"2022-04-05T05:01:14.185223Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df2= pd.DataFrame(hoodies_f_list, columns=['filename'])\ndf2['category']= ['hoodies_female'] * len(hoodies_f_list)\ndf3= pd.DataFrame(sweatshirt_list, columns=['filename'])\ndf3['category']= ['sweatshirt'] * len(sweatshirt_list)\ndf4= pd.DataFrame(sweatshirt_f_list, columns=['filename'])\ndf4['category']= ['sweatshirt_female'] * len(sweatshirt_f_list)\ndf5= pd.DataFrame(shirt_list, columns=['filename'])\ndf5['category']= ['shirt'] * len(shirt_list)\ndf6= pd.DataFrame(longsleeve_list, columns=['filename'])\ndf6['category']= ['longsleeve'] * len(longsleeve_list)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:01:16.766169Z","iopub.execute_input":"2022-04-05T05:01:16.766968Z","iopub.status.idle":"2022-04-05T05:01:16.782203Z","shell.execute_reply.started":"2022-04-05T05:01:16.766927Z","shell.execute_reply":"2022-04-05T05:01:16.781478Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"frames = [df, df2, df3, df4, df5, df6]\nresult = pd.concat(frames)\nresult","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:01:18.911962Z","iopub.execute_input":"2022-04-05T05:01:18.912533Z","iopub.status.idle":"2022-04-05T05:01:18.933523Z","shell.execute_reply.started":"2022-04-05T05:01:18.912485Z","shell.execute_reply":"2022-04-05T05:01:18.932886Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nresult['category'].value_counts().plot.bar()\nplt.title('Image data distribution histogram')\nplt.ylabel('Image count')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:01:23.805935Z","iopub.execute_input":"2022-04-05T05:01:23.806192Z","iopub.status.idle":"2022-04-05T05:01:24.018246Z","shell.execute_reply.started":"2022-04-05T05:01:23.806162Z","shell.execute_reply":"2022-04-05T05:01:24.017561Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Data is slightly imbalanced: class imbalance may leads you to believe your model is better than it really is.","metadata":{}},{"cell_type":"markdown","source":"## Generate train test data","metadata":{}},{"cell_type":"markdown","source":"We haven't split data into train/test yet. \nUse ImageDataGenerator to augment images automatically when training the model. \nrotation_range, width_shift_range, height_shift_range and zoom_range are specified as as factors, and also a horizontal flip and brightness adjustments are applied.","metadata":{}},{"cell_type":"code","source":"#train_test_generation\nimport tensorflow as tf\n\ndata_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale= 1/255.,                                                                                                                   \n                                                           rotation_range=0.2,\n                                                           width_shift_range=0.2,\n                                                           height_shift_range=0.2,\n                                                           zoom_range = [0.9,1.1], \n                                                           horizontal_flip=True,\n                                                           brightness_range=[0.9,1.1],\n                                                           validation_split = 0.2\n                                                            ) #validation: take 20%","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:01:41.752336Z","iopub.execute_input":"2022-04-05T05:01:41.752802Z","iopub.status.idle":"2022-04-05T05:01:43.438988Z","shell.execute_reply.started":"2022-04-05T05:01:41.752763Z","shell.execute_reply":"2022-04-05T05:01:43.438271Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# using keras flow_from_directory\n# generate training and test data. resize images\n\n\ntrain_data = data_gen.flow_from_directory(DATADIR,\n                                           target_size = (224,224),\n                                           class_mode = \"categorical\",\n                                           color_mode= \"rgb\",\n                                           seed = 5,\n                                           classes = [\"hoodies\",\"hoodies-female\",\"longsleeve\",\"shirt\",\"sweatshirt\",\"sweatshirt-female\"],\n                                           subset = \"training\",\n                                           )\n\ntest_data = data_gen.flow_from_directory(DATADIR,\n                                         target_size = (224,224),\n                                         class_mode = \"categorical\",\n                                         color_mode= \"rgb\",\n                                         classes = [\"hoodies\",\"hoodies-female\",\"longsleeve\",\"shirt\",\"sweatshirt\",\"sweatshirt-female\"],\n                                         seed = 5,\n                                         subset = \"validation\",\n                                         shuffle=False\n                                         )","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:02:09.502211Z","iopub.execute_input":"2022-04-05T05:02:09.502954Z","iopub.status.idle":"2022-04-05T05:02:10.582788Z","shell.execute_reply.started":"2022-04-05T05:02:09.502917Z","shell.execute_reply":"2022-04-05T05:02:10.581991Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"labels = list(train_data.class_indices.keys())","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:02:13.798061Z","iopub.execute_input":"2022-04-05T05:02:13.798379Z","iopub.status.idle":"2022-04-05T05:02:13.805104Z","shell.execute_reply.started":"2022-04-05T05:02:13.798341Z","shell.execute_reply":"2022-04-05T05:02:13.804340Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# visualizing the train dataset\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfig= plt.figure(figsize = (16,16))\nfig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\nfor i in range(25):\n  image,label = train_data.next()\n  plt.subplot(5,5,i+1)\n  plt.imshow(image[i],cmap=plt.cm.binary)\n  plt.title(labels[tf.argmax(label[i])])\n  plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:02:16.607311Z","iopub.execute_input":"2022-04-05T05:02:16.607584Z","iopub.status.idle":"2022-04-05T05:02:37.697451Z","shell.execute_reply.started":"2022-04-05T05:02:16.607552Z","shell.execute_reply":"2022-04-05T05:02:37.696806Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"For a simple CNN model, \nSteps are:\n\nBuild model,\nCompile model,\nTrain / fit the data to the model,\nEvaluate the model on the validation set,\nCarry out an error analysis of our model.\n\nConv2D: (32 filters of size 3 by 3) The features will be \"extracted\" from the image.\nMaxPooling2D: The images get half sized.\nFlatten: Transforms the format of the images from a 2d-array to a 1d-array of 150 150 3 pixel values.\nRelu : given a value x, returns max(x, 0).\nSoftmax: 6 neurons, probability that the image belongs to one of the classes.","metadata":{}},{"cell_type":"code","source":"# Building a CNN model \nimport tensorflow as tf\nfrom tensorflow.keras import layers\nmodel  = tf.keras.Sequential([\n                              \n                              layers.Conv2D(32, kernel_size= 3, activation=\"relu\", input_shape=(224,224,3)),\n                              layers.MaxPooling2D(pool_size= 2),\n\n                              layers.Conv2D(filters = 32, kernel_size= 3, activation= \"relu\"),\n                              layers.MaxPooling2D(pool_size= 2),\n                              layers.Conv2D(filters = 32, kernel_size= 3, activation= \"relu\"),\n                              layers.MaxPooling2D(pool_size= 2),\n\n                              layers.Flatten(),\n\n                              layers.Dense(128, activation=\"relu\"),\n                              layers.Dropout(0.5),\n\n                              layers.Dense(6, activation= \"softmax\")\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:09:13.214388Z","iopub.execute_input":"2022-04-05T05:09:13.214951Z","iopub.status.idle":"2022-04-05T05:09:13.275023Z","shell.execute_reply.started":"2022-04-05T05:09:13.214911Z","shell.execute_reply":"2022-04-05T05:09:13.274279Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:09:17.097418Z","iopub.execute_input":"2022-04-05T05:09:17.098182Z","iopub.status.idle":"2022-04-05T05:09:17.109329Z","shell.execute_reply.started":"2022-04-05T05:09:17.098140Z","shell.execute_reply":"2022-04-05T05:09:17.107972Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Then, we can compile:\n\nOptimizer: adam = RMSProp + Momentum\n\nMomentum = takes into account past gradient to have a better update.\n\nRMSProp = exponentially weighted average of the squares of past gradients.\n\nLoss function: we use sparse categorical crossentropy: each images belongs to one class only","metadata":{}},{"cell_type":"code","source":"# compiling the model\n\nmodel.compile(\n    loss = tf.keras.losses.categorical_crossentropy,\n    optimizer = tf.keras.optimizers.Adam(),\n    metrics = [\"accuracy\"]\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:09:23.427975Z","iopub.execute_input":"2022-04-05T05:09:23.428243Z","iopub.status.idle":"2022-04-05T05:09:23.440783Z","shell.execute_reply.started":"2022-04-05T05:09:23.428199Z","shell.execute_reply":"2022-04-05T05:09:23.440016Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# fitting data to the model\nbatch_size=1\nr= model.fit(train_data,\n          epochs = 5,\n          steps_per_epoch = len(train_data)/batch_size,\n          validation_data = test_data,\n          validation_steps = len(test_data)/batch_size,\n          )","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:09:26.898842Z","iopub.execute_input":"2022-04-05T05:09:26.899400Z","iopub.status.idle":"2022-04-05T05:43:17.339618Z","shell.execute_reply.started":"2022-04-05T05:09:26.899360Z","shell.execute_reply":"2022-04-05T05:43:17.338808Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model_evaluation = model.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:51:01.491064Z","iopub.execute_input":"2022-04-05T05:51:01.491350Z","iopub.status.idle":"2022-04-05T05:52:23.281920Z","shell.execute_reply.started":"2022-04-05T05:51:01.491319Z","shell.execute_reply":"2022-04-05T05:52:23.281187Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print(f\"Model Accuracy: {model_evaluation[1] * 100 : 0.2f} %\")","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:52:28.182620Z","iopub.execute_input":"2022-04-05T05:52:28.182878Z","iopub.status.idle":"2022-04-05T05:52:28.187421Z","shell.execute_reply.started":"2022-04-05T05:52:28.182849Z","shell.execute_reply":"2022-04-05T05:52:28.186525Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# visualizing the Test Data Predictions\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfig= plt.figure(figsize = (16,16))\nfor i in range(25):\n  image,label = test_data.next()\n  model_pred = model.predict(image)\n    \n  plt.subplot(5,5,i+1)\n  plt.imshow(image[i],cmap=plt.cm.binary)\n  plt.title(f\"Prediction: {labels[tf.argmax(model_pred[i])]} \\nOriginal : {labels[tf.argmax(label[i])]}\")\n  plt.subplots_adjust(top= 1.25)\n  plt.axis(\"off\")\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:53:24.346851Z","iopub.execute_input":"2022-04-05T05:53:24.347131Z","iopub.status.idle":"2022-04-05T05:53:46.378749Z","shell.execute_reply.started":"2022-04-05T05:53:24.347100Z","shell.execute_reply":"2022-04-05T05:53:46.377989Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def plot_accuracy_loss(r):\n    \"\"\"\n        Plot the accuracy and the loss during the training of the nn.\n    \"\"\"\n    fig = plt.figure(figsize=(10,5))\n\n    # Plot accuracy\n    plt.subplot(221)\n    plt.plot(r.history['accuracy'],'bo--', label = \"acc\")\n    plt.plot(r.history['val_accuracy'], 'ro--', label = \"val_acc\")\n    plt.title(\"train_acc vs val_acc\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epochs\")\n    plt.legend()\n\n    # Plot loss function\n    plt.subplot(222)\n    plt.plot(r.history['loss'],'bo--', label = \"loss\")\n    plt.plot(r.history['val_loss'], 'ro--', label = \"val_loss\")\n    plt.title(\"train_loss vs val_loss\")\n    plt.ylabel(\"loss\")\n    plt.xlabel(\"epochs\")\n\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:53:57.699718Z","iopub.execute_input":"2022-04-05T05:53:57.700188Z","iopub.status.idle":"2022-04-05T05:53:57.708721Z","shell.execute_reply.started":"2022-04-05T05:53:57.700152Z","shell.execute_reply":"2022-04-05T05:53:57.707820Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"plot_accuracy_loss(r)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:54:02.284251Z","iopub.execute_input":"2022-04-05T05:54:02.284951Z","iopub.status.idle":"2022-04-05T05:54:02.700306Z","shell.execute_reply.started":"2022-04-05T05:54:02.284913Z","shell.execute_reply":"2022-04-05T05:54:02.699610Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"X_test, y_test = next(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:54:08.688939Z","iopub.execute_input":"2022-04-05T05:54:08.689423Z","iopub.status.idle":"2022-04-05T05:54:09.437924Z","shell.execute_reply.started":"2022-04-05T05:54:08.689382Z","shell.execute_reply":"2022-04-05T05:54:09.437194Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Category index:\n\nhoodies = 0\nhoodies_female = 1\nlongsleeve = 2\nshirt = 3\nsweatshirt = 4\nsweatshirt-female = 5\nConfusion between:\n\nhoodies and sweatshirt\nhoodies-female and sweatshirt-female.\nShirts are more distinct so get correctly labeled the most often.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport seaborn as sns\nsns.set_style('darkgrid')\n\ndef cm_cr(test_gen, model):\n    preds=model.predict(test_gen)    \n    labels=test_gen.labels\n    classes=list(test_gen.class_indices.keys()) # ordered lst of class names \n    pred_list=[ ] # will store the predicted classes here\n    true_list=[]\n    for i, p in enumerate (preds):\n        index=np.argmax(p)\n        pred_list.append(classes[index])\n        true_list.append(classes[labels[i]])\n    y_pred=np.array(pred_list)\n    y_true=np.array(true_list)\n    clr = classification_report(y_true, y_pred, target_names=classes)\n    print(\"Classification Report:\\n----------------------\\n\", clr)\n    cm = confusion_matrix(y_true, y_pred )        \n    length=len(classes)\n    if length<8:\n        fig_width=8\n        fig_height=8\n    else:\n        fig_width= int(length * .5)\n        fig_height= int(length * .5)\n    plt.figure(figsize=(fig_width, fig_height))\n    sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n    plt.xticks(np.arange(length)+.5, classes, rotation= 90, fontsize=16)\n    plt.yticks(np.arange(length)+.5, classes, rotation=0, fontsize=16)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n\ncm_cr(test_data, model)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T05:54:26.145387Z","iopub.execute_input":"2022-04-05T05:54:26.146039Z","iopub.status.idle":"2022-04-05T05:55:48.527891Z","shell.execute_reply.started":"2022-04-05T05:54:26.145993Z","shell.execute_reply":"2022-04-05T05:55:48.527104Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# VGG16 model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nbase_model = tf.keras.applications.VGG16(input_shape = (224, 224, 3), \n                                         include_top = False, \n                                         weights = 'imagenet')\n\nbase_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:03:08.933123Z","iopub.execute_input":"2022-04-05T06:03:08.933612Z","iopub.status.idle":"2022-04-05T06:03:09.216795Z","shell.execute_reply.started":"2022-04-05T06:03:08.933568Z","shell.execute_reply":"2022-04-05T06:03:09.215941Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# building a VGG Model\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\n\nlast_layer = base_model.get_layer('block5_pool')\nprint('last layer of vgg : output shape: ', last_layer.output_shape)\nlast_output= last_layer.output\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(6, activation='softmax')(x)           \n\nvgg_model = Model(base_model.input, x) \n\n\n# compiling the model\nvgg_model.compile(\n    loss = tf.keras.losses.categorical_crossentropy,\n    optimizer = tf.keras.optimizers.Adam(),\n    metrics = [\"accuracy\"]\n    )\n# fitting data\n\nr= vgg_model.fit(\n    train_data,\n    epochs = 7,\n    steps_per_epoch = len(train_data),\n    validation_data = test_data,\n    validation_steps = len(test_data)\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:05:16.019586Z","iopub.execute_input":"2022-04-05T06:05:16.020384Z","iopub.status.idle":"2022-04-05T06:53:22.182368Z","shell.execute_reply.started":"2022-04-05T06:05:16.020342Z","shell.execute_reply":"2022-04-05T06:53:22.181562Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"vgg_model_evaluation = vgg_model.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:55:06.076405Z","iopub.execute_input":"2022-04-05T06:55:06.077185Z","iopub.status.idle":"2022-04-05T06:57:28.750030Z","shell.execute_reply.started":"2022-04-05T06:55:06.077147Z","shell.execute_reply":"2022-04-05T06:57:28.749267Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"print(f\"VGG16 Model Accuracy: {vgg_model_evaluation[1] * 100 :0.2f} %\")","metadata":{"execution":{"iopub.status.busy":"2022-04-05T07:04:05.097873Z","iopub.execute_input":"2022-04-05T07:04:05.098178Z","iopub.status.idle":"2022-04-05T07:04:05.103438Z","shell.execute_reply.started":"2022-04-05T07:04:05.098143Z","shell.execute_reply":"2022-04-05T07:04:05.102418Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"plot_accuracy_loss(r)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T07:07:26.641119Z","iopub.execute_input":"2022-04-05T07:07:26.641745Z","iopub.status.idle":"2022-04-05T07:07:27.044755Z","shell.execute_reply.started":"2022-04-05T07:07:26.641702Z","shell.execute_reply":"2022-04-05T07:07:27.044058Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# predicting and visualizing the test data\n\n\nfig= plt.figure(figsize = (16,16))\nfor i in range(25):\n  image,label = test_data.next()\n  vgg_model_pred = vgg_model.predict(image)\n    \n  plt.subplot(5,5,i+1)\n  plt.imshow(image[i],cmap=plt.cm.binary)\n  plt.title(f\"Prediction: {labels[tf.argmax(vgg_model_pred[i])]} \\nOriginal : {labels[tf.argmax(label[i])]}\")\n  plt.subplots_adjust(top= 1.25)\n  plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-05T07:08:23.160302Z","iopub.execute_input":"2022-04-05T07:08:23.161014Z","iopub.status.idle":"2022-04-05T07:08:49.806774Z","shell.execute_reply.started":"2022-04-05T07:08:23.160972Z","shell.execute_reply":"2022-04-05T07:08:49.806065Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"cm_cr(test_data, vgg_model)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T07:09:00.886659Z","iopub.execute_input":"2022-04-05T07:09:00.886936Z","iopub.status.idle":"2022-04-05T07:10:22.677345Z","shell.execute_reply.started":"2022-04-05T07:09:00.886904Z","shell.execute_reply":"2022-04-05T07:10:22.676621Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Save model\n\nvgg_model.save_weights('/kaggle/working/vgg_model.h5')\nmodel.save_weights('/kaggle/working/simple_CNN_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T07:18:56.308163Z","iopub.execute_input":"2022-04-05T07:18:56.308636Z","iopub.status.idle":"2022-04-05T07:18:56.633551Z","shell.execute_reply.started":"2022-04-05T07:18:56.308598Z","shell.execute_reply":"2022-04-05T07:18:56.632761Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"# Save Model ","metadata":{}}]}